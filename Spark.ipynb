{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘model_dir’: File exists\n",
      "--2019-11-01 05:20:01--  https://github.com/natashadsilva/scratch/blob/master/LinearModel.zip?raw=true\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://github.com/natashadsilva/scratch/raw/master/LinearModel.zip [following]\n",
      "--2019-11-01 05:20:01--  https://github.com/natashadsilva/scratch/raw/master/LinearModel.zip\n",
      "Reusing existing connection to github.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/natashadsilva/scratch/master/LinearModel.zip [following]\n",
      "--2019-11-01 05:20:01--  https://raw.githubusercontent.com/natashadsilva/scratch/master/LinearModel.zip\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8630 (8.4K) [application/zip]\n",
      "Saving to: ‘lmodel.zip’\n",
      "\n",
      "100%[======================================>] 8,630       --.-K/s   in 0.005s  \n",
      "\n",
      "2019-11-01 05:20:01 (1.74 MB/s) - ‘lmodel.zip’ saved [8630/8630]\n",
      "\n",
      "Archive:  lmodel.zip\n",
      "   creating: model_dir/stages/\n",
      "   creating: model_dir/stages/2_LinearRegression_805e3b7fa929/\n",
      "   creating: model_dir/stages/2_LinearRegression_805e3b7fa929/data/\n",
      " extracting: model_dir/stages/2_LinearRegression_805e3b7fa929/data/_SUCCESS  \n",
      "  inflating: model_dir/stages/2_LinearRegression_805e3b7fa929/data/part-00000-1e853830-28b3-48c7-844f-8016a8ab8bba-c000.snappy.parquet  \n",
      "  inflating: model_dir/stages/2_LinearRegression_805e3b7fa929/data/.part-00000-1e853830-28b3-48c7-844f-8016a8ab8bba-c000.snappy.parquet.crc  \n",
      "   creating: model_dir/stages/2_LinearRegression_805e3b7fa929/metadata/\n",
      "  inflating: model_dir/stages/2_LinearRegression_805e3b7fa929/metadata/.part-00000.crc  \n",
      " extracting: model_dir/stages/2_LinearRegression_805e3b7fa929/metadata/_SUCCESS  \n",
      "  inflating: model_dir/stages/2_LinearRegression_805e3b7fa929/metadata/part-00000  \n",
      "   creating: model_dir/stages/0_VectorAssembler_2856bc39a790/\n",
      "   creating: model_dir/stages/0_VectorAssembler_2856bc39a790/metadata/\n",
      "  inflating: model_dir/stages/0_VectorAssembler_2856bc39a790/metadata/.part-00000.crc  \n",
      " extracting: model_dir/stages/0_VectorAssembler_2856bc39a790/metadata/_SUCCESS  \n",
      "  inflating: model_dir/stages/0_VectorAssembler_2856bc39a790/metadata/part-00000  \n",
      "   creating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/\n",
      "   creating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/data/\n",
      "  inflating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/data/part-00000-e60c7bf7-a40e-4c90-a184-eb2d5f3f40d9-c000.snappy.parquet  \n",
      "  inflating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/data/.part-00000-e60c7bf7-a40e-4c90-a184-eb2d5f3f40d9-c000.snappy.parquet.crc  \n",
      " extracting: model_dir/stages/1_StandardScaler_adc0dbcf59b4/data/_SUCCESS  \n",
      "   creating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/metadata/\n",
      "  inflating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/metadata/.part-00000.crc  \n",
      " extracting: model_dir/stages/1_StandardScaler_adc0dbcf59b4/metadata/_SUCCESS  \n",
      "  inflating: model_dir/stages/1_StandardScaler_adc0dbcf59b4/metadata/part-00000  \n",
      "   creating: model_dir/metadata/\n",
      "  inflating: model_dir/metadata/.part-00000.crc  \n",
      " extracting: model_dir/metadata/_SUCCESS  \n",
      "  inflating: model_dir/metadata/part-00000  \n"
     ]
    }
   ],
   "source": [
    "!mkdir model_dir\n",
    "!wget -O lmodel.zip https://github.com/natashadsilva/scratch/blob/master/LinearModel.zip?raw=true\n",
    "!unzip -d model_dir  lmodel.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata  stages\r\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "credentials=getpass.getpass('Streaming Analytics credentials:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    " \n",
    "dirpath = os.getcwd()\n",
    "model_path = \"model_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamsx.ec\n",
    "import time\n",
    "import random\n",
    "from pyspark.ml import PipelineModel\n",
    "from pyspark.sql import SparkSession\n",
    "import warnings\n",
    "import logging\n",
    "import csv \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class LoadSparkModel:\n",
    "    def __init__(self, model_file):\n",
    "        self.model_path = model_path\n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        pass\n",
    "    def __enter__(self):\n",
    "        # Application is starting on the Streams runtime,\n",
    "        \n",
    "        logging.getLogger(\"SparkModel\").info(\"INFO: Loading Spark Model\")\n",
    "        # load json and create model\n",
    "        try :\n",
    "            self.sparkSession = SparkSession.builder.appName(\"Score Spark Model with Streams\").getOrCreate()\n",
    "            #get path to model at runtime\n",
    "            path_to_model = streamsx.ec.get_application_directory() + \"/etc/\" +  self.model_path\n",
    "            self.sparkModel = PipelineModel.load(path_to_model)\n",
    "            logging.getLogger(\"SparkModel\").info(\"INFO: Successfully loaded ,odel\")\n",
    "        except Exception as e:\n",
    "            logging.getLogger(\"SparkModel\").error(\"ERROR loading file \" +  str(e))\n",
    "        \n",
    "    def __call__(self, tpl):\n",
    "        logging.getLogger(\"SparkModel\").info(\"INFO: Going to run model on tuple\")\n",
    "        tpl_as_DF = self.sparkSession.createDataFrame([tpl])\n",
    "        result = self.sparkModel.transform(tpl_as_DF).collect()[0]\n",
    "        logging.getLogger(\"SparkModel\").debug(\"INFO: Ran model on tuple\")\n",
    "        tpl[\"prediction\"] = result.prediction\n",
    "        return tpl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<streamsx.topology.topology.Sink at 0x7f83722f2748>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create topology...change the name to something more meaningful\n",
    "from streamsx.topology.topology import Topology\n",
    "import streamsx.topology.context\n",
    "import numpy as np\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "topo = Topology(name=\"SparkScoring\")\n",
    "\n",
    "topo.add_file_dependency(model_path + \"/\", \"etc\")\n",
    "\n",
    "# add stream...delete and replace this with your streams and analytics\n",
    "# this is added so the topology will run (needs a source)\n",
    "# produces a random integer between 1 and 100 every tenth of a second\n",
    "\n",
    "import random, time\n",
    "\n",
    "def readings():\n",
    "    while True:\n",
    "        time.sleep(0.1)\n",
    "        time_now = 1541019341*1000\n",
    "        record_processed = 0\n",
    "        deviceID = np.random.randint(1, 3)\n",
    "        sensorID = np.random.randint(1, 50)\n",
    "        env_temp = np.random.normal(24.5, 2)  # ambient temp \n",
    "        time_now += np.random.randint(10,1500)\n",
    "        power = np.random.normal(10, 3) # power consumption\n",
    "        noise = np.random.normal(0,1.5)\n",
    "        temp = 1.3 * env_temp + 0.5 * power + 5 + noise\n",
    "\n",
    "        yield dict(device=int(deviceID), \n",
    "                   sensor=int(sensorID), ts=time_now, \n",
    "                   env_temp=float(env_temp),\n",
    "                   power=float(power), \n",
    "                   temperature=float(temp))\n",
    "\n",
    "\n",
    "source = topo.source(readings)\n",
    "predictions = source.isolate().map(LoadSparkModel(model_path))\n",
    "predictions.print()\n",
    "pv = predictions.view()\n",
    "sv = source.view\n",
    "topo.add_pip_package(\"pyspark\")\n",
    "source.print()\n",
    "# create a view to watch the stream data while running\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobId:  0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from streamsx.topology import topology, context\n",
    "import json\n",
    "\n",
    "def submit_from_notebook(topo, service_instance_name, credentials={}, verify_ssl=False):\n",
    "    isCloudPrivate = True\n",
    "    cfg = {}\n",
    "    try:\n",
    "        from icpd_core import icpd_util\n",
    "        cfg = icpd_util.get_service_instance_details(name=service_instance_name)\n",
    "        contextType = context.ContextTypes.DISTRIBUTED\n",
    "    except ImportError as error:\n",
    "        #Cloud Pak API unavailable\n",
    "        vs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\n",
    "        cfg = {}\n",
    "        cfg[ConfigParams.VCAP_SERVICES] = vs\n",
    "        cfg[ConfigParams.SERVICE_NAME] = service_name\n",
    "        contextType = context.ContextTypes.STREAMING_ANALYTICS_SERVICE\n",
    "        \n",
    "    cfg[context.ConfigParams.SSL_VERIFY] = verify_ssl\n",
    "    job = context.submit(contextType, topo, config=cfg)\n",
    "    return job\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fetch_tuples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2ed886c17734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_tuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'fetch_tuples'"
     ]
    }
   ],
   "source": [
    "#Submit\n",
    "\n",
    "job = submit_from_notebook(topo, service_name, credentials)\n",
    "\n",
    "if (job.id ):\n",
    "    print(\"Job with id \" + job.jobId  + \" was submitted\")\n",
    "else:\n",
    "    print (\"Error submitting job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
